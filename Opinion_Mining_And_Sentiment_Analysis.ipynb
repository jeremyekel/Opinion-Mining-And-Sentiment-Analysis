{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Opinion-Mining-And-Sentiment-Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hdU4Z5sWijfn",
        "ckkhL-emijgl",
        "phOqAYXkijh9",
        "twCE1oaJijh9",
        "e-ZJts5QijiR",
        "zbF34BR6iji1",
        "q67ydteQijjI",
        "EtGrQj7AijjI",
        "T9sOFUNDijjP",
        "_O5CvEQVijja",
        "m49UfOgBijjk"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X5-GCnvKijfl"
      },
      "source": [
        "# Opinion Mining & Sentiment Analysis: Deep Learning Techniques\n",
        "\n",
        "**Text Mining**\n",
        "\n",
        "_Prof. Gianluca Moro^, Dott. Ing. Nicola Piscaglia° – DISI, University of Bologna_\n",
        "\n",
        "^jeremymejia.ekel@studio.unibo.it\n",
        "\n",
        "\n",
        "°jeremymejia.ekel@bbscommunity.it\n",
        "\n",
        "\n",
        "**Bologna Business School** - Alma Mater Studiorum Università di Bologna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hdU4Z5sWijfn"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "luAnTvuXijfp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c16f954b-cb8c-4e84-8a8f-1ede1c025a16"
      },
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tMRsk6PDijf1",
        "colab": {}
      },
      "source": [
        "#download function\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "def download(file, url):\n",
        "    if not os.path.isfile(file):\n",
        "        urlretrieve(url, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4MldDiptijf-"
      },
      "source": [
        "### Dataset: Movie Reviews\n",
        "\n",
        "We have a collection of user reviews extracted from IMDb (the _Internet Movie Database_) labeled as positive or negative.\n",
        "\n",
        "We want to train a model to understand the positive or negative orientation of any review.\n",
        "\n",
        "We start by loading the training dataset, containing 25,000 samples with two attributes\n",
        "- `label` indicates the orientation of the review, can be \"pos\" or \"neg\"\n",
        "- `text` contains the full text of the review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dJZSpzfEijf_",
        "colab": {}
      },
      "source": [
        "download(\"imdb-train.csv.gz\", \"https://github.com/jeremyekel/Opinion-Mining-And-Sentiment-Analysis/raw/master/data/imdb-train.csv.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixJ7gGxvijgD",
        "colab": {}
      },
      "source": [
        "train_set = pd.read_csv(\"imdb-train.csv.gz\", sep=\"\\t\", names=[\"label\", \"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u20J-GJNijgH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7878f6c9-cf15-4b49-b38a-7144688850da"
      },
      "source": [
        "train_set.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7zi6nMDijgN",
        "colab": {}
      },
      "source": [
        "# Increasing the length of displayed text\n",
        "pd.options.display.max_colwidth = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s7tSOPO7ijgR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d13a460a-0888-4644-aa55-05c81bd4ef60"
      },
      "source": [
        "train_set.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>If you like adult comedy cartoons, like South Park, then this is nearly a similar format about t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>Bromwell High is nothing short of brilliant. Expertly scripted and perfectly delivered, this sea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                                                                 text\n",
              "0   pos  Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school l...\n",
              "1   neg  Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a t...\n",
              "2   pos  If you like adult comedy cartoons, like South Park, then this is nearly a similar format about t...\n",
              "3   neg  Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so w...\n",
              "4   pos  Bromwell High is nothing short of brilliant. Expertly scripted and perfectly delivered, this sea..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hfNSsvFDijgY",
        "colab": {}
      },
      "source": [
        "# Replacing <br /> with \\n\n",
        "def strip_tags(text):\n",
        "    return text.replace(\"<br />\", \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_QwwWL5ijge",
        "colab": {}
      },
      "source": [
        "train_set[\"text\"] = train_set[\"text\"].apply(strip_tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zBKiXF1Tijgh"
      },
      "source": [
        "Positive and negative reviews are evenly distributed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNlJoLAjijgi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2c36c3b5-ac9c-49e9-ba1f-6c1729af8114"
      },
      "source": [
        "train_set[\"label\"].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pos    12500\n",
              "neg    12500\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ckkhL-emijgl"
      },
      "source": [
        "## Multi-Layer Perceptron\n",
        "\n",
        "In their usual form, neural networks are composed by a stack of _densely connected_ layers of nodes: each node in a layer receives the output of all nodes of the underlying layer. Such networks are also known as _multi-layer perceptrons_.\n",
        "\n",
        "A MLP receives a vector as input and its topmost layer produces a vector as output, an arbitrary number of _hidden layers_ can be inserted inbetween to produce intermediate representations of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kXHi0YZoijgm",
        "colab": {}
      },
      "source": [
        "# Training a neural network for sentiment classification by initializing a vector space using tf.idf term weighting and filtering out very rare terms\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vect = TfidfVectorizer(min_df=3)\n",
        "\n",
        "train_dtm = vect.fit_transform(train_set[\"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "75ljR5t8ijgu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a2a66946-5f11-4588-d800-581c76f3f43b"
      },
      "source": [
        "# Extracting number of distinct terms in the vector space that are used to define the structure of the neural network\n",
        "num_terms = len(vect.get_feature_names())\n",
        "num_terms"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35852"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2BPRJINJijgz"
      },
      "source": [
        "We want our neural network to indicate in output the correct class of each review, either \"pos\" or \"neg\"\n",
        "\n",
        "For this, we must extract from the `label` column a \"target\" matrix, where each row contains the values which the network should give as output for each review\n",
        "- `[1, 0]` for positive reviews\n",
        "- `[0, 1]` for negative reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Ag3JHLcijgz",
        "colab": {}
      },
      "source": [
        "# Function to convert a given pos/neg labels series into a target matrix\n",
        "def make_target(labels):\n",
        "    return pd.DataFrame({\n",
        "        \"pos\": labels == \"pos\",\n",
        "        \"neg\": labels == \"neg\"\n",
        "    }).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ri-b_2sijg4",
        "colab": {}
      },
      "source": [
        "train_target = make_target(train_set[\"label\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ZnzNjEQijg8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d007a581-3b75-44ca-d222-376a8e404d68"
      },
      "source": [
        "train_target.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pos</th>\n",
              "      <th>neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pos  neg\n",
              "0    1    0\n",
              "1    0    1\n",
              "2    1    0\n",
              "3    0    1\n",
              "4    1    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nNu5VDT4ijhA",
        "colab": {}
      },
      "source": [
        "# Defining neural network structure\n",
        "from keras.models import Sequential\n",
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "syikncPfijhC"
      },
      "source": [
        "**First Model**\n",
        "\n",
        "- Using `softmax` activation function to ensure that the output is a valid probability distribution\n",
        "- We will never get a perfect `[1, 0]` as output in practice, but we will get outputs like `[0.99, 0.01]`\n",
        "- Specifying `input_dim` with the size of input vectors (distinct terms)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K387d-7uijhD",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense\n",
        "model.add(Dense(2, activation=\"softmax\", input_dim=num_terms))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zaNQ0pm-ijhF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3252f7f3-f53c-4ad1-d14e-bf1c93c98917"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 2)                 71706     \n",
            "=================================================================\n",
            "Total params: 71,706\n",
            "Trainable params: 71,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8J83C6k9ijhI"
      },
      "source": [
        "In this case we have 35,852×2 = 71,704 weights + 2 biases = 71,706 trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rh-BWg-bijhJ",
        "colab": {}
      },
      "source": [
        "# Compile to provide some general settings of the network and initialize accordingly the underlying TensorFlow data structures\n",
        "# Optimizer 'Adam' used to train the network\n",
        "# 'Cross Entropy' penalizes outputs which are not close to 1 on the correct class\n",
        "# Metrics can be computed for evaluation purposes \n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OoX-MmG1ijhN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4d2e346f-5c67-4d4d-cf55-67b70cac3553"
      },
      "source": [
        "# Fit the network 'train_dtm' and 'train_target'\n",
        "fit_history = model.fit(train_dtm, train_target, batch_size=200, epochs=10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 4s 166us/step - loss: 0.6566 - accuracy: 0.8057\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 4s 154us/step - loss: 0.5871 - accuracy: 0.8648\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 4s 153us/step - loss: 0.5327 - accuracy: 0.8770\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 4s 151us/step - loss: 0.4892 - accuracy: 0.8867\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 4s 153us/step - loss: 0.4535 - accuracy: 0.8929\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 4s 155us/step - loss: 0.4236 - accuracy: 0.9002\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 4s 154us/step - loss: 0.3982 - accuracy: 0.9061\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 4s 152us/step - loss: 0.3762 - accuracy: 0.9110\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 4s 155us/step - loss: 0.3571 - accuracy: 0.9149\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 4s 155us/step - loss: 0.3401 - accuracy: 0.9194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5ZAUswkRijhP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a5705810-4fe1-45fd-f662-2bd7e25246a5"
      },
      "source": [
        "plt.plot(fit_history.history[\"loss\"], \"ro-\")\n",
        "plt.plot(fit_history.history[\"accuracy\"], \"bo-\")\n",
        "plt.legend([\"Train loss\", \"Train accuracy\"]);"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g8IEIw07ijhQ"
      },
      "source": [
        "We can see in the plot how the loss progressively decreases and accuracy progressively increases through training epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c9xvYkoBijhR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c59b5877-df9a-4e0d-f1a1-0903b3253e6f"
      },
      "source": [
        "# Getting raw ouput given by the network\n",
        "model.predict(train_dtm[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.60513353, 0.39486644]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZHZq9_RWijhS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "614ce061-1d11-48d0-8221-d13763246ca1"
      },
      "source": [
        "# Getting predicted class index\n",
        "model.predict_classes(train_dtm[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g4S_QpdtijhU"
      },
      "source": [
        "Let's now evaluate the network on a separate test set of labeled reviews, provided in the `imdb-test.csv.gz` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mAloDfs_ijhU",
        "colab": {}
      },
      "source": [
        "download(\"imdb-test.csv.gz\", \"https://github.com/jeremyekel/Opinion-Mining-And-Sentiment-Analysis/raw/master/data/imdb-test.csv.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cLNJREo7ijhW",
        "colab": {}
      },
      "source": [
        "test_set = pd.read_csv(\"imdb-test.csv.gz\", sep=\"\\t\", names=[\"label\", \"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cCVKmpdHijhX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8221e7f9-c697-4beb-ab80-d9adb34065d8"
      },
      "source": [
        "test_set.head(5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the ter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>My boyfriend and I went to watch The Guardian.At first I didn't want to watch it, but I loved th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>This is a pale imitation of 'Officer and a Gentleman.' There is NO chemistry between Kutcher and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>My yardstick for measuring a movie's watch-ability is if I get squirmy. If I start shifting posi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                                                                 text\n",
              "0   pos  I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit ...\n",
              "1   neg  Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the ter...\n",
              "2   pos  My boyfriend and I went to watch The Guardian.At first I didn't want to watch it, but I loved th...\n",
              "3   neg  This is a pale imitation of 'Officer and a Gentleman.' There is NO chemistry between Kutcher and...\n",
              "4   pos  My yardstick for measuring a movie's watch-ability is if I get squirmy. If I start shifting posi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FcMI31SWijha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5546536f-0c5b-4fd6-b22a-4be6643a6fa7"
      },
      "source": [
        "test_set[\"label\"].value_counts()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pos    12500\n",
              "neg    12500\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OxuwoPh7ijhc",
        "colab": {}
      },
      "source": [
        "# Replacing <br /> with \\n\n",
        "test_set[\"text\"] = test_set[\"text\"].apply(strip_tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ez5mF5gDijhf",
        "colab": {}
      },
      "source": [
        "test_dtm = vect.transform(test_set[\"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JaIS1xc4ijhi",
        "colab": {}
      },
      "source": [
        "# Function to convert a given pos/neg labels series into a target matrix\n",
        "test_target = make_target(test_set[\"label\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q7apXO-kijhk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ee7a0a92-ffae-4b9d-9561-dc9607cf0489"
      },
      "source": [
        "# Evaluating the model\n",
        "model.evaluate(test_dtm, test_target)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 4s 155us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3992735678291321, 0.8705199956893921]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Gj_OgxTijhm"
      },
      "source": [
        "**Accuracy:** 0.869"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCTPxI-kRXO7",
        "colab_type": "text"
      },
      "source": [
        "**Second Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nyvQ21f2ijhm",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=num_terms))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QYqtpAIyijho"
      },
      "source": [
        "The output of these 128 will be fed to the output layer, composed as above by 2 nodes with softmax activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CjpSTK-3ijhp",
        "colab": {}
      },
      "source": [
        "# Output of 128 nodes will be fed to the output layer and composed as above by 2 nodes with softmax activation\n",
        "model.add(Dense(2, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "77gkoVQOijhr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "945dc017-527d-498f-a677-c607d7c2c17d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 128)               4589184   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 4,589,442\n",
            "Trainable params: 4,589,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "44A5mJmpijht",
        "colab": {}
      },
      "source": [
        "# Compile to provide some general settings of the network and initialize accordingly the underlying TensorFlow data structures\n",
        "# Optimizer 'Adam' used to train the network\n",
        "# 'Cross Entropy' penalizes outputs which are not close to 1 on the correct class\n",
        "# Metrics can be computed for evaluation purposes \n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tgf2l7fqijhu"
      },
      "source": [
        "To keep compute times limited, we fit this and subsequent networks running only 3 training epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cbNLJJMLijhu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "731bacb4-5bdf-413c-c8b8-a325eea9a125"
      },
      "source": [
        "# Fit the network 'train_dtm' and 'train_target'\n",
        "model.fit(train_dtm, train_target, batch_size=200, epochs=3)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 4s 172us/step - loss: 0.4111 - accuracy: 0.8478\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 4s 170us/step - loss: 0.1651 - accuracy: 0.9454\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 4s 171us/step - loss: 0.0878 - accuracy: 0.9769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f53d0068f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E7ZIIDp2ijhw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b6a4927e-f3d7-4122-b6af-19eb750f857d"
      },
      "source": [
        "# Evaluating the model\n",
        "model.evaluate(test_dtm, test_target)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 4s 153us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3186801377058029, 0.8703600168228149]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UxhI79Tuijhy"
      },
      "source": [
        "**Accuracy:** 0.871"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgjTo41KRjfa",
        "colab_type": "text"
      },
      "source": [
        "**Third Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LT68VXmSijhy"
      },
      "source": [
        "Replicating model using sigmoid activation in the hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xn9Rz1nNijhy",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(128, activation=\"sigmoid\", input_dim=num_terms),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x4V-pU5mijh0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c0e4ff9d-7bf7-41d4-9ea9-df3ddec62ccf"
      },
      "source": [
        "# Fit the network 'train_dtm' and 'train_target'\n",
        "model.fit(train_dtm, train_target, batch_size=200, epochs=3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 4s 171us/step - loss: 0.6103 - accuracy: 0.7912\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 4s 169us/step - loss: 0.4230 - accuracy: 0.8842\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 4s 169us/step - loss: 0.2874 - accuracy: 0.9166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f53d00688d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lSv2Qj2rijh2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "466c6a50-c0be-4095-b75d-adb0c3df51f7"
      },
      "source": [
        "# Evaluating the model\n",
        "model.evaluate(test_dtm, test_target)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 4s 154us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3239750177383423, 0.8792399764060974]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS9R2YB-Rx2G",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy:** 0.877"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "81z0mJXgijh3"
      },
      "source": [
        "Fourth Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WeIVFiroijh3",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(256, activation=\"sigmoid\", input_dim=num_terms),\n",
        "    Dense(64, activation=\"sigmoid\"),\n",
        "    Dense(16, activation=\"sigmoid\"),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4MRD8OIYijh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c55d038e-9edd-41a0-921a-79d82452f271"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 256)               9178368   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 9,195,890\n",
            "Trainable params: 9,195,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1PolQv6Eijh6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "83dea636-4040-4345-ba31-18f0a2913553"
      },
      "source": [
        "# Fit the network 'train_dtm' and 'train_target'\n",
        "model.fit(train_dtm, train_target, batch_size=200, epochs=3)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 4s 177us/step - loss: 0.6992 - accuracy: 0.5447\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 4s 173us/step - loss: 0.6162 - accuracy: 0.7732\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 4s 175us/step - loss: 0.2828 - accuracy: 0.8988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f536f78d748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VU-3khHcijh8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "13fc5843-e4e1-4578-bb7b-cf6128796c9d"
      },
      "source": [
        "# Evaluating the model\n",
        "model.evaluate(test_dtm, test_target)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 4s 153us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2789417101621628, 0.8850399851799011]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2hc5KlYSnHt",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy:** 0.886"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "phOqAYXkijh9"
      },
      "source": [
        "## Word Embedding\n",
        "\n",
        "A _word embedding_ model is a dictionary mapping each known word to a **N-dimensional vector**.\n",
        "\n",
        "The **gensim** library provides means to represent and build word embedding models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "twCE1oaJijh9"
      },
      "source": [
        "### Training a Word2Vec model\n",
        "\n",
        "We have a set of 5,000 movie reviews without any labeling: we can't train a sentiment classifier on them but we can train a word embedding model\n",
        "\n",
        "We read the compressed text file `imdb-unsup-5k.txt.gz`, containing one review per line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9OavdQnUijh-",
        "colab": {}
      },
      "source": [
        "download(\"imdb-unsup-5k.txt.gz\", \"https://github.com/jeremyekel/Opinion-Mining-And-Sentiment-Analysis/raw/master/data/imdb-unsup-5k.txt.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nyBYGNk3ijiA",
        "colab": {}
      },
      "source": [
        "with gzip.open(\"imdb-unsup-5k.txt.gz\", \"rt\") as f:\n",
        "    we_train_set = [strip_tags(line.strip()) for line in f]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y5GZooXWijiH"
      },
      "source": [
        "We have to preprocess each review by splitting text into tokens\n",
        "\n",
        "gensim, the library used to train the word embedding model, provides a simple utility function for this\n",
        "- alternatively any tokenization function can be used, e.g. `nltk.word_tokenize`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PfutSnpbijiH",
        "colab": {}
      },
      "source": [
        "from gensim.utils import simple_preprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "85unLKi1ijiI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "eff71f8e-a84e-44d5-a6e7-2bf7ace72478"
      },
      "source": [
        "%%time\n",
        "we_train_tokens = [simple_preprocess(text) for text in we_train_set]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.01 s, sys: 22.7 ms, total: 1.04 s\n",
            "Wall time: 1.04 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gQK-0EreijiJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a752b8f8-f13a-46a7-e0a5-0730c7fe690c"
      },
      "source": [
        "we_train_set[0][:82]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I admit, the great majority of films released before say 1933 are just not for me.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v0s69SngijiK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e1b57204-f803-46e3-ec00-70440ecc23a7"
      },
      "source": [
        "we_train_tokens[0][:8]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['admit', 'the', 'great', 'majority', 'of', 'films', 'released', 'before']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ja20QoU3ijiM"
      },
      "source": [
        "The most important parameter is the size of the word vectors we want to obtain\n",
        "- in the original Word2Vec paper 300 is indicated as a good value\n",
        "- here we use 50 as a tradeoff between accuracy and efficiency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TutdIlQPijiM",
        "colab": {}
      },
      "source": [
        "wordvecs_size = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5RqPntI9ijiO"
      },
      "source": [
        "Other relevant parameters are\n",
        "- the _window size_, i.e. the number of words before and after any word to consider as its context\n",
        "- the minimum appearances of a term to be included in the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ozAYVO4DijiO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cb648076-5263-4cc1-b9b9-60fc151e7c24"
      },
      "source": [
        "%%time\n",
        "wv_model = gensim.models.Word2Vec(\n",
        "    we_train_tokens,\n",
        "    size=wordvecs_size,\n",
        "    window=5,\n",
        "    min_count=5\n",
        ")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14.2 s, sys: 52.1 ms, total: 14.2 s\n",
            "Wall time: 8.52 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uqu4z2HdijiQ"
      },
      "source": [
        "Our Word2Vec model is now trained, we can get a reference to the word->vector mapping itself `wv` and drop the rest of the model object to free some memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NJ9oaU44ijiQ",
        "colab": {}
      },
      "source": [
        "wv = wv_model.wv\n",
        "del wv_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e-ZJts5QijiR"
      },
      "source": [
        "### Exploring the word embedding model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6cqNQUweijiR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "754df143-5ebe-4cc5-c71d-4ab7312a648d"
      },
      "source": [
        "# Distinct terms in the model\n",
        "len(wv.vocab)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12070"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KnGJ4SZpijiT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "122bc393-d135-4a44-e1d5-b68c43ed2d75"
      },
      "source": [
        "# First commong terms\n",
        "wv.index2word[:10]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'and', 'of', 'to', 'is', 'in', 'it', 'this', 'that', 'as']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tte_Q-IjijiU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bb574dc4-7902-46c4-d8b9-93aa5f7422e6"
      },
      "source": [
        "# Sample of vector 'excellent' word\n",
        "wv.word_vec(\"excellent\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.0692371e-02, -2.5783143e+00, -1.3506367e+00,  2.3988014e-01,\n",
              "        1.5038668e-01,  5.4138020e-02,  5.5156940e-01,  7.9598844e-01,\n",
              "        4.7793037e-01,  1.2590929e+00,  5.4246068e-01, -7.9931659e-01,\n",
              "        5.0815415e-01, -5.8446544e-01,  2.2800026e+00,  8.5092521e-01,\n",
              "        4.6415684e-01,  3.5409518e-02,  1.3116820e+00, -6.8750924e-01,\n",
              "       -3.7776271e-01,  3.4756464e-01, -6.1254758e-01,  8.0525899e-01,\n",
              "        1.0199246e+00, -1.3023434e+00, -1.8168657e+00,  4.2487559e-01,\n",
              "        1.1203139e+00,  1.1096715e+00,  9.2268783e-01, -7.4720854e-01,\n",
              "       -1.3459345e+00, -1.1870738e+00,  1.5507081e-02,  1.3777466e+00,\n",
              "       -4.7890621e-01, -5.2592331e-01, -1.2132574e+00, -1.5812813e+00,\n",
              "        1.0392408e+00,  1.0805709e+00,  2.2071030e+00,  2.4046151e-01,\n",
              "        1.1384501e+00,  2.2097389e-01, -5.4840070e-01,  1.9764748e-01,\n",
              "       -2.6135790e-01, -2.1806841e-03], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A6YbcAZtijiV",
        "colab": {}
      },
      "source": [
        "# Compute and cache normalized vectors\n",
        "wv.init_sims()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EHTppXSMijiW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "def543a4-4023-4899-9196-e3c44a002d09"
      },
      "source": [
        "# True indicates to normalize the vector\n",
        "wv.word_vec(\"excellent\", True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.26859695e-02, -3.60652328e-01, -1.88925877e-01,  3.35542224e-02,\n",
              "        2.10359562e-02,  7.57277850e-03,  7.71530420e-02,  1.11342162e-01,\n",
              "        6.68524802e-02,  1.76120818e-01,  7.58789256e-02, -1.11807704e-01,\n",
              "        7.10801557e-02, -8.17545131e-02,  3.18924755e-01,  1.19026668e-01,\n",
              "        6.49258494e-02,  4.95305238e-03,  1.83476925e-01, -9.61681902e-02,\n",
              "       -5.28411157e-02,  4.86170352e-02, -8.56826156e-02,  1.12638921e-01,\n",
              "        1.42666161e-01, -1.82170644e-01, -2.54141569e-01,  5.94312251e-02,\n",
              "        1.56708524e-01,  1.55219868e-01,  1.29064769e-01, -1.04518875e-01,\n",
              "       -1.88268140e-01, -1.66046843e-01,  2.16911687e-03,  1.92717984e-01,\n",
              "       -6.69889823e-02, -7.35656917e-02, -1.69709384e-01, -2.21188247e-01,\n",
              "        1.45368099e-01,  1.51149318e-01,  3.08727622e-01,  3.36355455e-02,\n",
              "        1.59245402e-01,  3.09096351e-02, -7.67098069e-02,  2.76467558e-02,\n",
              "       -3.65585126e-02, -3.05032183e-04], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3xhp5jb5ijiX",
        "colab": {}
      },
      "source": [
        "# Using 'cosine_similarities' function to compute similarity among the vectors\n",
        "similarities_to_excellent = wv.cosine_similarities(\n",
        "    wv.word_vec(\"excellent\"),\n",
        "    wv.vectors\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q2YQMfI4ijiZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "681af4aa-61f3-4389-b67e-84b4a7c9a736"
      },
      "source": [
        "similarities_to_excellent[:5]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.11190797,  0.21383691,  0.12925905, -0.1857107 ,  0.2399035 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yX-uIkfLijic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7b6500ff-3605-4f7f-a4d1-aad046373303"
      },
      "source": [
        "pd.Series(\n",
        "    similarities_to_excellent,\n",
        "    wv.index2word\n",
        ").sort_values(ascending=False).head(10)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "excellent      1.000000\n",
              "outstanding    0.922494\n",
              "impressive     0.895074\n",
              "brilliant      0.889264\n",
              "amazing        0.883686\n",
              "directing      0.876207\n",
              "fine           0.872892\n",
              "terrific       0.857629\n",
              "fantastic      0.857597\n",
              "direction      0.855202\n",
              "dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ThbC8lr_ijih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "68f77456-4f56-49f6-f635-4e5af7277bd9"
      },
      "source": [
        "# Similar words\n",
        "wv.most_similar(\"excellent\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('outstanding', 0.922494113445282),\n",
              " ('impressive', 0.8950737714767456),\n",
              " ('brilliant', 0.8892644047737122),\n",
              " ('amazing', 0.8836863040924072),\n",
              " ('directing', 0.8762070536613464),\n",
              " ('fine', 0.8728923797607422),\n",
              " ('terrific', 0.8576288223266602),\n",
              " ('fantastic', 0.8575965166091919),\n",
              " ('direction', 0.8552022576332092),\n",
              " ('superb', 0.8542619943618774)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rLCZfn4Tijij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "31de2bf9-0516-4a96-9a28-302db130c43c"
      },
      "source": [
        "wv.most_similar(\"terrible\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('horrible', 0.9485824108123779),\n",
              " ('awful', 0.9209786653518677),\n",
              " ('hilarious', 0.9109424948692322),\n",
              " ('ok', 0.8960175514221191),\n",
              " ('ridiculous', 0.8959105610847473),\n",
              " ('decent', 0.8881834745407104),\n",
              " ('predictable', 0.8697757720947266),\n",
              " ('boring', 0.863764226436615),\n",
              " ('scary', 0.8630543947219849),\n",
              " ('cool', 0.8560620546340942)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VmXN-LSoijil"
      },
      "source": [
        "Another powerful function of word embedding models is to find words with specific syntactic and semantic relationships using vector arithmetics\n",
        "\n",
        "Consider the relationship _\"man\" is to \"woman\" as \"actor\" is to X_ where the model has to find out that X = \"actress\"\n",
        "\n",
        "Word2Vec produces vectors in such a way that _\"man\" - \"woman\" = \"actor\" - X_, so we can find X as the term whose vector is closest to _\"actor\" + \"woman\" - \"man\"_\n",
        "\n",
        "Let's produce the vector representation of X..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2Qt-RL2ijim",
        "colab": {}
      },
      "source": [
        "composition = (wv.word_vec(\"actor\", True)\n",
        "             + wv.word_vec(\"woman\", True)\n",
        "             - wv.word_vec(\"man\", True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UrKeBry3ijio",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "58d0a7f9-39aa-420a-ce99-f4b24e2490f5"
      },
      "source": [
        "pd.Series(\n",
        "    wv.cosine_similarities(composition, wv.vectors),\n",
        "    wv.index2word\n",
        ").sort_values(ascending=False).head(10)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "actor          0.922859\n",
              "actress        0.908202\n",
              "role           0.879228\n",
              "chaney         0.815216\n",
              "performance    0.806804\n",
              "bruce          0.799823\n",
              "oscar          0.787288\n",
              "talented       0.784481\n",
              "star           0.782140\n",
              "davis          0.780560\n",
              "dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XUswR_k4ijiq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "84ffacfd-28bd-4257-b346-d479c121561f"
      },
      "source": [
        "# Similar words\n",
        "wv.most_similar(\n",
        "    positive=[\"actor\", \"woman\"],\n",
        "    negative=[\"man\"]\n",
        ")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actress', 0.9082022905349731),\n",
              " ('role', 0.8792279958724976),\n",
              " ('chaney', 0.8152158856391907),\n",
              " ('performance', 0.8068039417266846),\n",
              " ('bruce', 0.7998225688934326),\n",
              " ('oscar', 0.7872880101203918),\n",
              " ('talented', 0.7844809889793396),\n",
              " ('star', 0.7821401953697205),\n",
              " ('davis', 0.7805596590042114),\n",
              " ('accent', 0.7779046893119812)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b6AiDV0Oijir"
      },
      "source": [
        "According to randomness in the training process, the correct answer \"actress\" might be the most similar word or very close to it, but still the confidence of the model is limited"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OUhtaQjaijir"
      },
      "source": [
        "We proceed our analysis on a pretrained GloVe (_Global Vectors_) word embedding model, whose training procedure is similar to Word2Vec."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LtxBxAWlijir",
        "colab": {}
      },
      "source": [
        "download(\"glove.npz\", \"https://github.com/jeremyekel/Opinion-Mining-And-Sentiment-Analysis/raw/master/data/glove.npz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ro3dVXHVijis",
        "colab": {}
      },
      "source": [
        "with np.load(\"glove.npz\") as f:\n",
        "    glove_words = f[\"words\"]\n",
        "    glove_vectors = f[\"vectors\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zc8Ezgocijiu",
        "outputId": "e7eed67a-e5c9-49dc-81e7-fb4e7da488af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "wordvecs_size = glove_vectors.shape[1]\n",
        "wordvecs_size"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "810O0gzOijiv",
        "colab": {}
      },
      "source": [
        "# Creating the word embedding model from the words\n",
        "wv = gensim.models.KeyedVectors(wordvecs_size)\n",
        "wv[glove_words.tolist()] = glove_vectors\n",
        "wv.init_sims()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ts4n0Lzoijiw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7495e0cb-e541-4c7e-ac2e-76b704dc4b43"
      },
      "source": [
        "# Similar words\n",
        "wv.most_similar(\n",
        "    positive=[\"actor\", \"woman\"],\n",
        "    negative=[\"man\"]\n",
        ")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actress', 0.9073609113693237),\n",
              " ('comedian', 0.6890829205513),\n",
              " ('actresses', 0.6826434135437012),\n",
              " ('screenwriter', 0.6554961204528809),\n",
              " ('starred', 0.6533135175704956),\n",
              " ('starring', 0.6514240503311157),\n",
              " ('actors', 0.6402771472930908),\n",
              " ('dancer', 0.6378583908081055),\n",
              " ('singer', 0.6346279382705688),\n",
              " ('filmmaker', 0.6279778480529785)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pmdt3u5Lijiy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "afe845f6-1c8d-4926-ba9c-c7930c4f01c4"
      },
      "source": [
        "# Similar words\n",
        "wv.most_similar(\n",
        "    positive=[\"mouse\", \"dogs\", \"cats\"],\n",
        "    negative=[         \"dog\",  \"cat\"]\n",
        ")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mice', 0.710668683052063),\n",
              " ('rabbits', 0.681904673576355),\n",
              " ('rodents', 0.6771590709686279),\n",
              " ('rats', 0.6427716016769409),\n",
              " ('animals', 0.6243681907653809),\n",
              " ('monkeys', 0.6002902984619141),\n",
              " ('ferrets', 0.5910987854003906),\n",
              " ('mammals', 0.5888075828552246),\n",
              " ('foxes', 0.5750464200973511),\n",
              " ('raccoons', 0.5635854005813599)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W6xfzMegijiz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0d2cd618-7cde-45cf-f08c-af0588a021ba"
      },
      "source": [
        "# Similar words\n",
        "wv.most_similar(\n",
        "    positive=[\"france\", \"rome\",  \"berlin\"],\n",
        "    negative=[          \"italy\", \"germany\"]\n",
        ")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('paris', 0.7584174871444702),\n",
              " ('cairo', 0.6146870851516724),\n",
              " ('london', 0.5959091186523438),\n",
              " ('versailles', 0.5937519669532776),\n",
              " ('vienna', 0.5896108150482178),\n",
              " ('brussels', 0.5775601863861084),\n",
              " ('petersburg', 0.5704914331436157),\n",
              " ('palace', 0.5681281089782715),\n",
              " ('sorbonne', 0.5556104183197021),\n",
              " ('strasbourg', 0.555298388004303)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dtlGXDtDiji0"
      },
      "source": [
        "Another method provided by the model is `doesnt_match` finding the word which is the least related to the others in a given list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggqHsg-Ciji0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "36abf90a-2671-4aff-a0ab-8524251103a0"
      },
      "source": [
        "# Word is the least related\n",
        "wv.doesnt_match([\"cat\", \"mouse\", \"dog\", \"keyboard\", \"frog\"])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'keyboard'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zbF34BR6iji1"
      },
      "source": [
        "### Representing text with word embedding\n",
        "\n",
        "Leveraging the word embedding model in a neural network for sentiment classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fl71GbuEiji1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7e663b7c-1aad-4079-f67d-b66b9a11432b"
      },
      "source": [
        "%%time\n",
        "train_tokens = [gensim.utils.simple_preprocess(text) for text in train_set[\"text\"]]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.95 s, sys: 176 ms, total: 5.12 s\n",
            "Wall time: 5.07 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LeDkVtk2iji2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d8e4f973-6b84-4e31-8259-21944d2a0e00"
      },
      "source": [
        "train_set[\"text\"][0][:34]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bromwell High is a cartoon comedy.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ExehX2fviji3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "71808a72-b618-44d6-a4a4-5dae28529f0e"
      },
      "source": [
        "train_tokens[0][:5]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bromwell', 'high', 'is', 'cartoon', 'comedy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w3iIvvERiji4",
        "colab": {}
      },
      "source": [
        "# Converting lists of text tokens into lists of indices of terms in the word embedding model\n",
        "train_indices = [\n",
        "    [wv.vocab[word].index for word in text if word in wv.vocab]\n",
        "    for text in train_tokens\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DIsZ8aQniji5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3ce94acd-6267-4baf-fceb-60d1913da4e2"
      },
      "source": [
        "train_indices[0][:5]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[152, 14, 7362, 2841, 20]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2OZ7A9BIiji6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e7297ec6-d067-4ddb-f482-abb84441a150"
      },
      "source": [
        "# Translating back to words\n",
        "[wv.index2word[i] for i in train_indices[0][:5]]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['high', 'is', 'cartoon', 'comedy', 'it']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kbiYYgapiji8",
        "colab": {}
      },
      "source": [
        "# Represnting each review with normalized vector mean of words contained in it.\n",
        "train_we_repr = np.vstack([wv.vectors_norm[indices].mean(0) for indices in train_indices])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nImeccYXiji9",
        "colab": {}
      },
      "source": [
        "# Creating MLP network with one hidden layer accepting such vectors in input\n",
        "model = Sequential([\n",
        "    Dense(128, activation=\"sigmoid\", input_dim=wordvecs_size),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M7LO5JNKiji-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1a0d725a-9240-4c17-896a-dd22acde6c2f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 13,186\n",
            "Trainable params: 13,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sVyXA1WkijjA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cb8b3e9a-76bb-409b-b9f8-3bac2d9924fd"
      },
      "source": [
        "# Fit the network 'train_we_repr' and 'train_target'\n",
        "model.fit(train_we_repr, train_target, batch_size=20, epochs=10)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 3s 116us/step - loss: 0.6527 - accuracy: 0.6302\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 3s 116us/step - loss: 0.5701 - accuracy: 0.7241\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 3s 114us/step - loss: 0.5183 - accuracy: 0.7560\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 3s 114us/step - loss: 0.4927 - accuracy: 0.7707\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 3s 113us/step - loss: 0.4775 - accuracy: 0.7787\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 3s 113us/step - loss: 0.4694 - accuracy: 0.7824\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 3s 112us/step - loss: 0.4647 - accuracy: 0.7845\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 3s 113us/step - loss: 0.4613 - accuracy: 0.7853\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 3s 113us/step - loss: 0.4570 - accuracy: 0.7894\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 3s 113us/step - loss: 0.4558 - accuracy: 0.7882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5333293908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yBNZ24koijjB",
        "colab": {}
      },
      "source": [
        "# Preprocessing test reviews\n",
        "# Extracting tokens and coverting them to indices\n",
        "test_tokens = [gensim.utils.simple_preprocess(text) for text in test_set[\"text\"]]\n",
        "test_indices = [\n",
        "    [wv.vocab[word].index for word in text if word in wv.vocab]\n",
        "    for text in test_tokens\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M_hMmd8aijjC",
        "colab": {}
      },
      "source": [
        "# Obtaining Word of Vectors means for each review\n",
        "test_we_repr = np.vstack([wv.vectors_norm[indices].mean(0) for indices in test_indices])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XjiIP9UpijjF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3c1588a8-a67e-4e7a-bab5-8fbe173caf7f"
      },
      "source": [
        "# Evaluating the model\n",
        "model.evaluate(test_we_repr, test_target)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 43us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.45939572566986087, 0.7887200117111206]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sapvLiNFijjH"
      },
      "source": [
        "**Accuracy:** 0.781"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q67ydteQijjI"
      },
      "source": [
        "## Recurrent neural networks\n",
        "\n",
        "MLPs are _feed-forward_ networks: their output at any time is only dependent from their input at the same time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EtGrQj7AijjI"
      },
      "source": [
        "### Sequential data\n",
        "Leveraging the word embedding model, we represent each review with the **sequence of word vectors** for the terms contained in it\n",
        "- in this way, we consider both the identity of words (the vectors) and their order!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t9ig7jcbijjJ"
      },
      "source": [
        "We need to make all sequences of the same length (the T term above): we set a desired sequence size T, then we trim longer sequences to that size (taking the final T elements) and pad shorter sequences with null values: Keras' `pad_sequences` function does this\n",
        "- larger T values would make training much slower"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xrJ9m443ijjK",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_words = 200\n",
        "train_seq = pad_sequences(train_indices, max_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uzShlwn7ijjL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "57a13dae-e479-4989-816c-6f15bb5b794f"
      },
      "source": [
        "train_seq"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,    12,    20, 75360],\n",
              "       [    0,     0,     0, ...,    30,   541,  3442],\n",
              "       [    0,     0,     0, ...,   219,   191,   219],\n",
              "       ...,\n",
              "       [    0,     0,     0, ..., 29080,  1075,    48],\n",
              "       [  460,     4,    30, ...,   227,    30,  4254],\n",
              "       [    0,     0,     0, ...,  1666,    13, 13664]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eso0uIZoijjO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c88540f5-2652-43aa-c5fa-1aa65f152056"
      },
      "source": [
        "train_seq.shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T9sOFUNDijjP"
      },
      "source": [
        "### Building the network\n",
        "\n",
        "Let's now create a neural network which gets such sequences as input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dCVlPbB9ijjP",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n0_fyctsijjQ",
        "colab": {}
      },
      "source": [
        "# Inserting an Embedding layer, which translates each received value into the word vector from the embedding model\n",
        "from keras.layers import Embedding\n",
        "model.add(Embedding(\n",
        "    input_dim=len(wv.vocab),    # number of distinct vocabulary terms\n",
        "    output_dim=wordvecs_size,   # size of word vectors (S)\n",
        "    input_length=max_words,     # length of sequences (T)\n",
        "    weights=[wv.vectors],       # word vectors\n",
        "    trainable=False\n",
        "))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-iusgIq9ijjR"
      },
      "source": [
        "_Gated Recurrent Units_ (GRU) are a simplified version of _Long Short-Term Memory_ (LSTM) units, which can potentially hold information in memory across many time steps; we use here a layer of 128 GRU cells\n",
        "\n",
        "_Dropout_ randomly drops (sets to zero) a given ratio of input values at each time step: it is a technique to prevent model overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dE2umoGqijjS",
        "colab": {}
      },
      "source": [
        "from keras.layers import GRU\n",
        "model.add(GRU(128, dropout=0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oQQXSfhLijjT",
        "colab": {}
      },
      "source": [
        "model.add(Dense(2, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z8XBIRFIijjU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8b6d20e2-104a-4576-e672-cbda6ba483b7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 100)          10000000  \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 128)               87936     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 10,088,194\n",
            "Trainable params: 88,194\n",
            "Non-trainable params: 10,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vIP-bm4SijjV"
      },
      "source": [
        "We can now compile the network and train it on the padded sequences of word indices\n",
        "- training of RNNs is quite slow, we again limit training to 3 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lpWVXKdoijjW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f0aa27cc-37d3-4ad4-b5ad-6c36d9c917fb"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(train_seq, train_target, batch_size=200, epochs=3)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6090 - accuracy: 0.6562\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 45s 2ms/step - loss: 0.4557 - accuracy: 0.7894\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 45s 2ms/step - loss: 0.3904 - accuracy: 0.8270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f531fdc29e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qo6fNOX1ijjY",
        "colab": {}
      },
      "source": [
        "test_seq = pad_sequences(test_indices, max_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5oOOjw0KijjZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f17eb9cc-f467-40a4-f158-c9367edeed44"
      },
      "source": [
        "# Evaluating model\n",
        "model.evaluate(test_seq, test_target)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 27s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36640770977020265, 0.8379600048065186]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_O5CvEQVijja"
      },
      "source": [
        "## Cross domain classification\n",
        "\n",
        "We trained our network on reviews of movies and tested its ability to classify sentiment in reviews of movies\n",
        "\n",
        "The `yelp-test-10k.csv.gz` file contains 10,000 labeled user reviews about restaurants extracted from Yelp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ruAqMWKuijja",
        "colab": {}
      },
      "source": [
        "download(\"yelp-test-10k.csv.gz\", \"https://github.com/jeremyekel/Opinion-Mining-And-Sentiment-Analysis/raw/master/data/yelp-test-10k.csv.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E9WF8IjCijjb",
        "colab": {}
      },
      "source": [
        "xdom_set = pd.read_csv(\"yelp-test-10k.csv.gz\", sep=\"\\t\", names=[\"label\", \"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VVAq0BiMijjc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c695ba22-74c6-4651-b59e-c92d8bca2882"
      },
      "source": [
        "xdom_set.head(5)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>U can go there n check the car out. If u wanna buy 1 there? That's wrong move! If u even want a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>I have no idea why some people give bad reviews about this place. It goes to show you, you can ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>Disgusting!  Had a Groupon so my daughter and I tried it out.  Very outdated and gaudy 80's sty...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!! It's very convenient and surrounded by a lot of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                                                                 text\n",
              "0   pos   My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfec...\n",
              "1   neg   U can go there n check the car out. If u wanna buy 1 there? That's wrong move! If u even want a...\n",
              "2   pos   I have no idea why some people give bad reviews about this place. It goes to show you, you can ...\n",
              "3   neg   Disgusting!  Had a Groupon so my daughter and I tried it out.  Very outdated and gaudy 80's sty...\n",
              "4   pos   Rosie, Dakota, and I LOVE Chaparral Dog Park!!! It's very convenient and surrounded by a lot of..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4pH0eU8nijjf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f89deddc-430b-4b0f-9988-0a7106708a66"
      },
      "source": [
        "xdom_set[\"label\"].value_counts()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pos    5000\n",
              "neg    5000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dbvFQXrHijji",
        "colab": {}
      },
      "source": [
        "# Preprocessing\n",
        "xdom_set[\"text\"] = xdom_set[\"text\"].apply(strip_tags)\n",
        "xdom_tokens = [gensim.utils.simple_preprocess(text) for text in xdom_set[\"text\"]]\n",
        "xdom_indices = [\n",
        "    [wv.vocab[word].index for word in text if word in wv.vocab]\n",
        "    for text in xdom_tokens\n",
        "]\n",
        "xdom_seq = pad_sequences(xdom_indices, max_words)\n",
        "xdom_target = make_target(xdom_set[\"label\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kSNJx7E-ijjj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cb54d9fe-a22f-4e74-d9b0-fd8a1e9681d8"
      },
      "source": [
        "# Evaluating model\n",
        "model.evaluate(xdom_seq, xdom_target)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 11s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3896024509429932, 0.817300021648407]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m49UfOgBijjk"
      },
      "source": [
        "## Fine tuning the network\n",
        "\n",
        "In the `yelp-train-2k.csv.gz` we have a set of 2,000 labeled Yelp reviews which can be used for training\n",
        "\n",
        "We would like to make use of these in-domain reviews, without throwing away the model trained on the richer set of cross-domain reviews\n",
        "\n",
        "We can \"tune\" the trained model with an additional training run on the new set of reviews, thus making it more oriented to the new domain and still using knowledge from the other\n",
        "\n",
        "Let's load and view a summary of the file..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nxlsR6mBijjk",
        "colab": {}
      },
      "source": [
        "download(\"yelp-train-2k.csv.gz\", \"https://github.com/jeremyekel/Opinion-Mining-And-Sentiment-Analysis/raw/master/data/yelp-train-2k.csv.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DxpazN57ijjk",
        "colab": {}
      },
      "source": [
        "tune_set = pd.read_csv(\"yelp-train-2k.csv.gz\", sep=\"\\t\", names=[\"label\", \"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MCs5AdGVijjl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8941c172-b549-4fe7-bc49-e1566edacf65"
      },
      "source": [
        "tune_set.head(5)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>Great local yoga studio. Had flexible hours like early morning and late night to fit any schedu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>I've been craving a good roast beef sandwich for a few days now, and finally had the chance to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>Super tasty, love the cozy atmosphere, excellent and friendly service!  The naan was a bit thin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>After waiting 4 days to get an appointment, Flores was a no show and didn't even bother to call.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>I have had my kitty Miller for 8 years. She has never been to any other vet.  I like this place...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                                                                 text\n",
              "0   pos   Great local yoga studio. Had flexible hours like early morning and late night to fit any schedu...\n",
              "1   neg   I've been craving a good roast beef sandwich for a few days now, and finally had the chance to ...\n",
              "2   pos   Super tasty, love the cozy atmosphere, excellent and friendly service!  The naan was a bit thin...\n",
              "3   neg     After waiting 4 days to get an appointment, Flores was a no show and didn't even bother to call.\n",
              "4   pos   I have had my kitty Miller for 8 years. She has never been to any other vet.  I like this place..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K8DJfLp6ijjm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f3ff2d11-f8b8-4607-e9e4-754db9736ca3"
      },
      "source": [
        "tune_set[\"label\"].value_counts()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pos    1000\n",
              "neg    1000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sljc7xaKijjn",
        "colab": {}
      },
      "source": [
        "# Preprocessing\n",
        "tune_set[\"text\"] = tune_set[\"text\"].apply(strip_tags)\n",
        "tune_tokens = [gensim.utils.simple_preprocess(text) for text in tune_set[\"text\"]]\n",
        "tune_indices = [\n",
        "    [wv.vocab[word].index for word in text if word in wv.vocab]\n",
        "    for text in tune_tokens\n",
        "]\n",
        "tune_seq = pad_sequences(tune_indices, max_words)\n",
        "tune_target = make_target(tune_set[\"label\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c0UcqKYrijjo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b9ade343-a708-4513-90c3-090b37ec506b"
      },
      "source": [
        "model.fit(tune_seq, tune_target, epochs=5, batch_size=200)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3863 - accuracy: 0.8250\n",
            "Epoch 2/5\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3084 - accuracy: 0.8655\n",
            "Epoch 3/5\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2893 - accuracy: 0.8775\n",
            "Epoch 4/5\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2678 - accuracy: 0.8955\n",
            "Epoch 5/5\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2415 - accuracy: 0.8985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f531fb05400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jKPuFAkRijjp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "80ada3ac-a097-4ac7-f120-9fd5f51d5521"
      },
      "source": [
        "model.evaluate(xdom_seq, xdom_target)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 11s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21754012694358826, 0.9143000245094299]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvhCFpvrs3M9",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy:** 0.876"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a3MGAFWQijjq"
      },
      "source": [
        "We successfully boosted the model accuracy, combining even limited knowledge of the target domain with large knowledge extracted from a different domain"
      ]
    }
  ]
}